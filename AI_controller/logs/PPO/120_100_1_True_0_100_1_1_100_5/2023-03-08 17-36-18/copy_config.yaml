
#simulation config
sample_time : 0.1

#Vehicle parameters
constraints:
  forces: #(according to SNAME)
    X: #surge
      upper: 180
      lower: -60
    N: #torque among yaw
      upper: 50
      lower: -50


#MPC controller parameters
MPC:
  debug: True
  prediction_horizon: 10
  sample_time: 0.1
  solver : 'ipopt'

  nlp_options: #tips: https://github-wiki-see.page/m/casadi/casadi/wiki/FAQ%3A-how-to-pass-options-to-solvers#:~:text=Options%20for%20nonlinear%20programming%20solvers%20are%20passed%20in,%3D%20nlpsol%20%28%27solver_name%27%2C%27ipopt%27%2Cnlp%2Coptions%29%20Using%20Opti%20%3A%20opti.solver%20%28%27ipopt%27%2Coptions%29
    print_time: False

  options:
      ipopt:       #ipopt options: https://coin-or.github.io/Ipopt/OPTIONS.html
        print_level : 1 # can be between 0-12 and will print different at  each solution
        max_iter: 100
        linear_solver:


#AI-controller parameters
env: #invironment parameters
  debug: False
  render_mode: #'human'  #'human' #will render a plot every 1000 epoch (not working as it should)
  sim_length: 0.5 # how long to run the simulation between each action (seconds)
  sample_time: 0.1 # how long integration steps are used in the simulation
  observation_space: # used to normalize the observations to the neural network
    lower: 0
    higher: 600 # represents the 2 x radius range of the positioning system
  world_size: [-200,200] #represent min and max in a quadratic box shape (for now this does not
  time_out: 120
  random_target: True
  fixed_target: [-20,-20]
  target_spawn_region: 100 #defines the radius of the region where the target will randomly appear, used in training if the AI
  target_confident_region: 1 # defines a confident region around the target,

  #Tuning coefficients for the reward function in the environment
  c1: 0 # tuning coefficient for distance to target reward
  c2: 100 # tuning coefficient for target reached reward
  c3: 1 # tuning coefficient for controller penalty
  c4: 1 # tuning coefficient for intermediate time penalty
  c5: 100 # tuning parameter for time out penalty
  c6: 5 # tuning parameter for distance towards target change rate (speed towards target)
  c7: 2 # tuning coefficient for desired heading error


continue_training: False
n_stacked_frames: 4 # how many stacked frames to use, makes a simple "Memory" for the agent
total_timesteps: 1_000_000
model: 'PPO' #prefix of the model


